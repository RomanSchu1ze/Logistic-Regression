% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fScore.R
\name{fScore}
\alias{fScore}
\title{Fisher Scoring algorithm}
\usage{
fScore(X, y, maxIter = 100, rate = 1, accuracy = 0.01, ...)
}
\arguments{
\item{X}{A numerical matrix of format n x k}

\item{y}{A numerical vector of format n x 1}

\item{maxIter}{A scalar defining the maximum number of iterations}

\item{rate}{Learning rate}

\item{accuracy}{tells when to stop the algorithm}

\item{...}{optional arguments}
}
\value{
a list containing: 
\itemize{
\item vector of estimated coefficients
\item probability for each observation
\item number of fisher scoring iterations
\item convergence 
}
}
\description{
\code{fScore} is a nonlinear optimization technique to determine the best estimator for a
set of unknown parameters. In case of logistic regression the parameter of interest is beta. 
Gradient descent is an iterative search process, where
one starts at a random point on the log likelihood function.  In this case the starting value(s) are chosen to be zero.
Further necessary inputs are a set of predictors \code{X} and a binary response \code{y}.
The user of this function can also choose the maximum number of iterations the algorithm
is searching for an optimum of beta. Additionaly the learning rate and the accuracy can be
manually determined.
}
\examples{
set.seed(1)
X <- replicate(2, rnorm(100))
# Add a vector of ones as first column to estimate Intercept
X <- cbind(1, X)
z <- 2 * X[, 2] + 3 * X[, 3]
# Use function logsitic and check help pages for further information
y <- rbinom(100, 1, logistic(z))
fScore(X, y)

}
